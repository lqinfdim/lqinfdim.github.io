---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi, there. Iâ€™m Qi Li, a CS PhD student of Tsinghua University. I also sever as research intern at HKUST-GZ. Previously, I obtained my master's degree of engineering from Tsinghua University in 2022. Before that, I got my bachelor's degree in engineering from Lanzhou University.

My current research interests are efficient LLM, machine learning system for LLM, understanding deep learning (espically LLM) from both theoretical and empirical view. 
Any collaboration is welcomed, feel free to drop me an email.

<!-- My research interests include efficient large language models  and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->

# ğŸ”¥ News

- *2026.01*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICLR 2026.
- *2025.10*: &nbsp;ğŸ‰ğŸ‰ Our preprint about RLLM serving is available on [ArXiv](https://arxiv.org/abs/2510.18672) and [HuggingFace](https://huggingface.co/papers/2510.18672).
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by NeurIPS 2025. 
- *2025.05*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ACL 2025. 
- *2025.04*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ISIT 2025.  
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by NeurIPS 2024. 
- *2024.05*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ACL 2024.





# ğŸ“– Educations

- *2025.08 - current*, Tsinghua University, PhD Student.
- *2019.08 - 2022.08*, Tsinghua University, Master of Engineering. 
- *2014.09 - 2018.06*, Lanzhou University, Bachelor of Engineering.


<!--

# ğŸ’» Preprint Papers

- Qi Li, Junpan Wu, Xiang Liu, Yuxin Wang, Zeyu Li, Zhenheng Tang, Yuhan Chen, Shaohuai Shi, Xiaowen Chu. Reasoning Language Model Inference Serving Unveiled: An Empirical Study. Online, Oct, 2025.
  [ArXiv](https://arxiv.org/abs/2510.18672) [HuggingFace](https://huggingface.co/papers/2510.18672).

  -->


# ğŸ“ Selected Publications 

<!--
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

- Li Q, Wu J, Liu X, et al. Reasoning language model inference serving unveiled: An empirical study[J]. Long Paper of The Fourteenth International Conference on Learning Representations (ICLR26, Tsinghua-A). 
- Li Q. et.al. AdaEdit: Advancing Continuous Knowledge Editing For Large Language Models. Long paper of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025, CCF-A).
- Qingyue Zhang, Haohao Fu, Guanbo Huang, Yaoyuan Liang, Chang Chu, Tianren Peng, Yanru Wu, Qi Li, Yang Li, Shao-Lun Huang. A High-Dimensional Statistical Method for Optimizing Transfer Quantities in Multi-Source Transfer Learning. Main Track Paper of the Thirty-nith Annual Conference on Neural Information Processing Systems (NeurIPS 2025, CCF-A).
- T. Peng, Q. Li, S.-L. Huang, "On the Optimal Second-Order Convergence Rate of Minimax Estimation Under Weighted MSE," IEEE International Symposium on Information Theory, Jun., 2025. (ISIT 2025 Oral, Tsinghua B)
- Li Q. et.al. Should We Really Edit Language Models? On the Comprehensive Evaluation of Edited Language Models. Main Track Paper of the Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024, CCF-A).
- Li, Q. et al. Can We Continually Edit Language Models? On the Knowledge Attenuation in Sequential Model Editing. Long paper of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024, CCF-A).
- Li, Q. et.al. Harnessing the Power of Pre-trained Vision-Language Models for Efficient Medical Report Generation. Long Paper of 32nd ACM International Conference on Information and Knowledge Management (CIKM 2023 Oral, CCF-B). 

# ğŸ– Honors and Awards

- *2015.12*, First Class Scholarship for Outstanding Students, Lanzhou University.
- *2017.12*, First Class Scholarship for Outstanding Students, Lanzhou University.    
- *2015.12*, Outstanding Student at Lanzhou University.
- *2016.12*, Outstanding Student at Lanzhou University.
- *2017.12*, Outstanding Student at Lanzhou University.
- *2020.12*, Scholarship for Excellent Students, Tsinghua Shenzhen International Graduate School. 


# ğŸ‘” Academic Services

* Reviewer: ACL ARR'25,26, ICML'25,26, ICLR'25,26, NeurIPS'24,25, CVPR'26, EMNLP'23,24,25, ICASSP'23,24,25,26, ECAI'23,24, ICME'24,25,26

<!--
# ğŸ’» Experience

- *2023.09 - Current*, Research Intern, HKUST(GZ), China.
- *2022.10 - 2023.01*, Research Intern, Tsinghua University, China. -->

<!--
ğŸ’» ğŸ“•
# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->
